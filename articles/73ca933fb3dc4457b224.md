---
title: "いまさら fluentdをはじめてみた Apache + Elasticsearch + Kib"
emoji: "📝"
type: "tech"
topics: Fluentd CentOS6.5 Elasticsearch kibana3
published: true
---

# いまさら fluentd はじめてみる５（完結編）
紆余曲折しましたが、やっと「[もう何番煎じだ？](http://blog.johtani.info/blog/2013/06/10/fluent-es-kibana/)」ぐらい同じレベルでインストールできました。いやはやインストールしたバージョンが[bug](http://qiita.com/murachi1208/items/39e3ef65ad859e2d9705)あったおかげ？で勉強色々しました。これでようやっとスタートラインにたてましたｗ。で、本題「Apache + fluentd + Elasticsearch + Kibana」 ということで（本当に何番煎じ？）完結編です。

> [fluentd + Elasticsearch + Kibanaでデータ集計サーバを作る](http://qiita.com/nagane/items/5b6d3fc1a8706146fb0b)

![apache.png](https://qiita-image-store.s3.amazonaws.com/0/44540/6ca576dc-5299-ae9f-9f3b-348a0c596e12.png)

# File descriptor, Kernel パラメータの設定
[vm](http://qiita.com/murachi1208/items/5b429cb7cedf76164e67) を２つ用意します。これは単にサービス側と解析側とインスタンスを分離し明確にしたいだけ（趣味的な問題）なので適宜読み飛ばして頂いても結構です。でも fluentd は、ファイルディスクリプタを結構使うらしいのでデフォルト 1024 より大きい値にしておきます。

```
$ sudo vi /etc/security/limits.conf
root soft nofile 65536
root hard nofile 65536
* soft nofile 65536
* hard nofile 65536

$ ulimit -n （システムを再起動）
```

```
$ sudo vi /etc/sysctl.conf
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.ip_local_port_range = 10240    65535

$ sysctl -w
```

# fluentd のインストール
ダウングレードした td-agent 0.10.45 を入れる、理由は最新版がまだアレなので。

```
$ sudo su
# curl -L http://toolbelt.treasuredata.com/sh/install-redhat.sh | sh
$ sudo yum remove td-agent-1.1.20-0.x86_64
$ sudo yum install td-agent-1.1.19-0.x86_64
$ td-agent --version
td-agent 0.10.45
```

で、yum の fastestmirror を導入していたり update すると折角ダウングレードしたのが最新化されてしまうので ```/etc/yum.conf``` に以下を追加する。

```
exclude=td-*
```

# 受信側（コレクター側）の設定

## elasticsearch のプラグインを導入
受信側（コレクター側）に fluentd の [elasticsearch プラグイン](https://github.com/uken/fluent-plugin-elasticsearch)を導入、gemで入れるとき libcurl-devel, gcc が必須です。

```
# yum install libcurl-devel gcc
# /usr/lib64/fluent/ruby/bin/gem install fluent-plugin-elasticsearch
```

## Elasticsearch をインストール
外部レポジトリの追加(EPEL)をおこないます。また Elasticsearch には java が必要なのでそれもインストールします（個人的には、java 入れるの凄い嫌だけどｗ）。あとは形態素解析器の Kuromoji プラグインもついでにインストールしてもよさげかもしれません。

```
# rpm --import http://packages.elasticsearch.org/GPG-KEY-elasticsearch
# vi /etc/yum.repos.d/elasticsearch.repo
[elasticsearch-1.1]
name=Elasticsearch repository for 1.1.x packages
baseurl=http://packages.elasticsearch.org/elasticsearch/1.1/centos
gpgcheck=1
gpgkey=http://packages.elasticsearch.org/GPG-KEY-elasticsearch
enabled=1

# yum install elasticsearch java-1.7.0-openjdk
# chkconfig --add elasticsearch
# chkconfig elasticsearch on
# service elasticsearch start
```

んでもって、動作をチェックする。

```
$ curl -X GET http://localhost:9200/
{
  "status" : 200,
  "name" : "Wilbur Day",
  "version" : {
    "number" : "1.1.2",
    "build_hash" : "e511f7b28b77c4d99175905fac65bffbf4c80cf7",
    "build_timestamp" : "2014-05-22T12:27:39Z",
    "build_snapshot" : false,
    "lucene_version" : "4.7"
  },
  "tagline" : "You Know, for Search"
}
```

## Apache のインストール
ここは、いつものごとくす。ServerName を弄っておくとワーニングがでないのであれしときます。kibana を起動するだけなので nginx でもokなのでここも趣味の問題です。

```
# yum install httpd
# /etc/init.d/httpd start
# chkconfig httpd on
```

## kibana のインストール
3.1.0 最新版をインストール(2014/7/4時点)。

```
# curl -sL https://download.elasticsearch.org/kibana/kibana/kibana-3.1.0.tar.gz | sudo tar zxf - -C /var/www/html
# mv /var/www/html/kibana-3.1.0 /var/www/html/kibana
# /etc/init.d/httpd restart
```

## アクセス
http://localhost/kibana にアクセスして kinaba の初期画面が表示されることを確認する。
![kibana.png](https://qiita-image-store.s3.amazonaws.com/0/44540/e9662824-9689-352d-b407-43f17532d629.png)

## fluentd の定義
転送された内容を確認する意味で ```type stdout``` を指定してます。 運用始める前は ```/var/log/td-agent/td-agent.log``` に出力された内容を確認し微調整しながら理解＆定義した方がいいです。

```
<source>
  type forward
  port 24224
</source>


<match apache.**>
  type copy

  <store>
    type stdout
  </store>

  <store>
    type elasticsearch
    host elasticsearch IPアドレス
    port 9200
    type_name access_log_2
    logstash_format true
    logstash_prefix apache_access
    logstash_dateformat %Y%m
  </store>

 </match>
```

# 送信側（エージェント側）

## fluentd の定義
fluentd の apache2 プラグインを使用しデコードした内容を elasticsearch をインストールしてあるサーバに転送します。ここでも ```type stdout``` を指定してます。 運用始める前は ```/var/log/td-agent/td-agent.log``` を見つつ設定した方がベストです。

```
<source>
  type tail
  path /var/log/httpd/access_log
  tag apache.combined
  pos_file /var/log/td-agent/httpd-access.log.pos
  format apache2
</source>

<match apache.**>
  type copy

  <store>
    type stdout
  </store>

  <store>
    type forward
    buffer_chunk_limit 256m
    buffer_queue_limit 128
    flush_interval 5s
    <server>
      host elasticsearch IPアドレス
      port 24224
    </server>
  </store>
</match>
```

# kibana
fluentd の設定、Elasticsearch でデータが溜まってくるとようやくデータを可視化する準備が整います。ちなみにデータが蓄積されてないと kibana で解析できないというか面白くないので適当に、wget とか curl でサービス側を叩いておくこと、

## kibana の使い方
きっと環境セットアップより難しいかも。わたしも勉強中です。
![kibana2.png](https://qiita-image-store.s3.amazonaws.com/0/44540/6ba2b01b-d330-79ad-7e8a-5cde243f159b.png)


> [fluentd + Elasticsearch + Kibanaで始めるログ解析 (セットアップ編)](http://blog.excale.net/index.php/archives/1929)

# 次回
fluentd を多段構成にしつつ冗長化構成したりと遊んで、もとい勉強してみるつもり

> [fluentdで始めるログ管理【フォワード設定まとめ】](http://blog.excale.net/index.php/archives/1997)







